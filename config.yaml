vM: # vM: von Mises
  root_dir: "/work/tamamori/von-mises/"
  data_dir: "data/"
  trainset_dir: "basic5000/" # you must download the dataset & specify its dirname
  evalset_dir: "onoma300/"   # you must download the dataset & specify its dirname
  resample_dir: "resample_16k/"
  resample_trim_dir: "resample_16k_trim/"
  label_dir: "label/"
  feat_dir: "feat/"
  stats_dir: "stats/"
  model_dir: "model/"
  demo_dir: "demo/"
  score_dir: "score/"
  fig_dir: "fig/"

preprocess:
  resample_rate: 16000
  n_jobs: 6
  sec_per_split: 0.9  # in seconds (DO NOT EDIT!)
  repo_url: "https://github.com/sarulab-speech/jsut-label/archive/refs/heads/master.zip"
  repo_name: "jsut-label-master"

feature:
  sample_rate: 16000  # sampling frequency
  win_length: 512     # analysis window length (frame length)
  hop_length: 128     # hop length (frame shift length)
  window: "hann"      # window type
  n_fft: 512          # FFT length
  gla_iter: 10        # iterations of Griffin-Lim algorithm

model:
  input_dim: 257
  hidden_dim: 1024
  n_layers: 4  # number of hidden-to-hidden layers
  win_range: 2 # window width when configuring input features
  
training:
  n_epoch: 500
  n_batch: 256
  num_workers: 1
  grd_weight: 0.1  # weight for group delay loss
  model_file: "model.pytorch"
  optim:
    optimizer:
      name: RAdam
      params:  # add items according to optimizer
        lr: 0.001  # learning rate
    lr_scheduler:
      name: StepLR
      params:
        step_size: 100  # period of learning rate decay (StepLR)
        gamma: 0.8    # multiplicative factor of learning rate decay (StepLR)
  use_scheduler: True  # True: enable scheduler
  use_grad_clip: True  # True enable gradient clipping
  grad_max_norm: 10  # clipping value

demo:
  gla: True  # True: reconstruction with Griffin-Lim method
  pesq_band: "wb"  # "wb": wideband or "nb": narrowband
  stoi_extended: False  # True: extended STOI
